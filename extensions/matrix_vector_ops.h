#pragma once

#ifndef _INCLUDE_MATRIX_VECTOR_OPS
#define _INCLUDE_MATRIX_VECTOR_OPS

#include "custom_types.h"
//#include "optional.h"
#include <torch/extension.h>

torch::Tensor matmul(
	const torch::Tensor &vectorMatrixA, const torch::Tensor &vectorMatrixB,
	const bool transposeA, const bool invertA,
	const bool transposeB, const bool invertB,
	const bool transposeOutput, const bool invertOutput
);
std::vector<torch::Tensor> matmulGrad(
	const torch::Tensor &vectorMatrixA, const torch::Tensor &vectorMatrixB, const torch::Tensor &outputGrad,
	const bool transposeA, const bool invertA,
	const bool transposeB, const bool invertB,
	const bool transposeOutput, const bool invertOutput
);

torch::Tensor VectorToDiagMatrix(const torch::Tensor &vectors);
torch::Tensor InvertMatrix(const torch::Tensor &matrices, const bool inPlace);

// CUDA device code, only enable when compiling cuda code
#ifdef __CUDACC__

#include "transformations.h"

template<typename scalar_t, int DIMS>
__device__ inline
Vector<scalar_t, DIMS> loadVectorFromChannels(const scalar_t* vectors, const index_t flatPos, const index_t stride){
	Vector<scalar_t, DIMS> v;
	for(index_t i=0; i<DIMS; ++i){
		v.a[i] = vectors[flatPos + i*stride];
	}
	return v;
}

template<typename scalar_t, int DIMS>
__device__ inline
void writeVectorToChannels(const Vector<scalar_t, DIMS> &v, scalar_t* vectors, const index_t flatPos, const index_t stride){
	for(index_t i=0; i<DIMS; ++i){
		vectors[flatPos + i*stride] = v.a[i];
	}
}

template<typename scalar_t, int DIMS>
__device__ inline
MatrixSquare<scalar_t, DIMS> loadMatrixFromChannels(const scalar_t* matrices, const index_t flatPos, const index_t stride){
	MatrixSquare<scalar_t, DIMS> m;
	for(index_t row=0; row<DIMS; ++row){
		for(index_t col=0; col<DIMS; ++col){
			m.a[row][col] = matrices[flatPos + (row*DIMS + col)*stride];
		}
	}
	return m;
}

template<typename scalar_t, int DIMS>
__device__ inline
void writeMatrixToChannels(const MatrixSquare<scalar_t, DIMS> &m, scalar_t* matrices, const index_t flatPos, const index_t stride){
	for(index_t row=0; row<DIMS; ++row){
		for(index_t col=0; col<DIMS; ++col){
			matrices[flatPos + (row*DIMS + col)*stride] = m.a[row][col];
		}
	}
}

template<typename scalar_t, int DIMS>
__device__ inline
MatrixSquare<scalar_t, DIMS> loadMatrixFromChannelsTransposed(const scalar_t* matrices, const index_t flatPos, const index_t stride){
	MatrixSquare<scalar_t, DIMS> m;
	for(index_t row=0; row<DIMS; ++row){
		for(index_t col=0; col<DIMS; ++col){
			m.a[col][row] = matrices[flatPos + (row*DIMS + col)*stride];
		}
	}
	return m;
}

template<typename scalar_t, int DIMS>
__device__ inline
void writeMatrixToChannelsTransposed(const MatrixSquare<scalar_t, DIMS> &m, scalar_t* matrices, const index_t flatPos, const index_t stride){
	for(index_t row=0; row<DIMS; ++row){
		for(index_t col=0; col<DIMS; ++col){
			matrices[flatPos + (row*DIMS + col)*stride] = m.a[col][row];
		}
	}
}

#endif //__CUDACC__

#endif //_INCLUDE_MATRIX_VECTOR_OPS